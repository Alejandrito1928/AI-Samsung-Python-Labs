{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb52c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Antes de la limpieza ---\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "--- Datos faltantes por columna ---\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "--- Después de la limpieza ---\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age              0\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alere\\AppData\\Local\\Temp\\ipykernel_21092\\94053324.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(promedio_edad, inplace=True)\n",
      "C:\\Users\\alere\\AppData\\Local\\Temp\\ipykernel_21092\\94053324.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['embark_town'].fillna(ciudad_comun, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar datos (ejemplo)\n",
    "df = sns.load_dataset('titanic')\n",
    "print(\"--- Antes de la limpieza ---\")\n",
    "print(df.isnull().sum()) \n",
    "\n",
    "# 1. DIAGNÓSTICO\n",
    "print(\"--- Datos faltantes por columna ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. ELIMINAR (Cirugía)\n",
    "# La columna 'deck' (cubierta) tiene demasiados huecos. La matamos.\n",
    "# axis=1 (columna), thresh=500 (borrar si tiene menos de 500 datos válidos)\n",
    "df_limpio = df.dropna(axis=1, thresh=500)\n",
    "\n",
    "# 3. RELLENAR NÚMEROS (Media)\n",
    "# A 'age' le faltan datos, pero es importante. Rellenamos con el promedio.\n",
    "promedio_edad = df['age'].mean()\n",
    "df['age'].fillna(promedio_edad, inplace=True)\n",
    "\n",
    "# 4. RELLENAR CATEGORÍAS (Moda)\n",
    "# A 'embark_town' le faltan poquitos. Asumimos la ciudad más común.\n",
    "ciudad_comun = df['embark_town'].value_counts().idxmax()\n",
    "df['embark_town'].fillna(ciudad_comun, inplace=True)\n",
    "\n",
    "print(\"\\n--- Después de la limpieza ---\")\n",
    "print(df.isnull().sum()) # Debería salir casi todo en 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbee9cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Datos Faltantes Iniciales ---\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "--- Resultado Final (Ceros = Limpio) ---\n",
      "age            0\n",
      "embark_town    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CARGA ---\n",
    "df = sns.load_dataset('titanic')\n",
    "print(\"--- 1. Datos Faltantes Iniciales ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# --- 2. LIMPIEZA (Sin Warnings) ---\n",
    "\n",
    "# A) Eliminar columna 'deck' (porque faltan demasiados datos)\n",
    "df_limpio = df.dropna(axis=1, thresh=500)\n",
    "\n",
    "# B) Eliminar filas sin 'age' (en una copia aparte para probar)\n",
    "df_sin_filas = df.dropna(subset=['age'], axis=0)\n",
    "\n",
    "# --- 3. IMPUTACIÓN (Rellenar) ---\n",
    "df_rellenado = df.copy()\n",
    "\n",
    "# C) Rellenar Edad con Promedio (FORMA MODERNA)\n",
    "promedio_edad = df['age'].mean()\n",
    "# Así se hace ahora para evitar el warning:\n",
    "df_rellenado['age'] = df_rellenado['age'].fillna(promedio_edad)\n",
    "\n",
    "# D) Rellenar Ciudad con Moda (FORMA MODERNA)\n",
    "ciudad_comun = df['embark_town'].value_counts().idxmax()\n",
    "# Así se hace ahora:\n",
    "df_rellenado['embark_town'] = df_rellenado['embark_town'].fillna(ciudad_comun)\n",
    "\n",
    "# --- 4. VERIFICACIÓN FINAL ---\n",
    "print(\"\\n--- Resultado Final (Ceros = Limpio) ---\")\n",
    "# Solo mostramos las columnas que tocamos para no marearte\n",
    "print(df_rellenado[['age', 'embark_town']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c5090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. DataFrame Original (Con Duplicados) ---\n",
      "    ID Nombre           Email\n",
      "0  101    Ana    ana@test.com\n",
      "1  102   Beto   beto@test.com\n",
      "2  103  Carla  carla@test.com\n",
      "3  101    Ana    ana@test.com\n",
      "4  104  David  david@test.com\n",
      "5  102   Beto  beto@nuevo.com\n",
      "------------------------------\n",
      "Filas duplicadas EXACTAS: 1\n",
      "\n",
      "--- Mostrando las filas que son copias ---\n",
      "    ID Nombre         Email\n",
      "3  101    Ana  ana@test.com\n",
      "\n",
      "--- 2. Limpieza Exacta (Se fue la copia de Ana) ---\n",
      "    ID Nombre           Email\n",
      "0  101    Ana    ana@test.com\n",
      "1  102   Beto   beto@test.com\n",
      "2  103  Carla  carla@test.com\n",
      "4  104  David  david@test.com\n",
      "5  102   Beto  beto@nuevo.com\n",
      "\n",
      "--- 3. Limpieza por ID (Se fue el segundo Beto) ---\n",
      "    ID Nombre           Email\n",
      "0  101    Ana    ana@test.com\n",
      "1  102   Beto   beto@test.com\n",
      "2  103  Carla  carla@test.com\n",
      "4  104  David  david@test.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. CREACIÓN DE DATOS SUCIOS ---\n",
    "data = {\n",
    "    'ID': [101, 102, 103, 101, 104, 102],\n",
    "    'Nombre': ['Ana', 'Beto', 'Carla', 'Ana', 'David', 'Beto'],\n",
    "    'Email': ['ana@test.com', 'beto@test.com', 'carla@test.com', 'ana@test.com', 'david@test.com', 'beto@nuevo.com']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- 1. DataFrame Original (Con Duplicados) ---\")\n",
    "print(df)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 2. DETECCIÓN (El Diagnóstico) ---\n",
    "# duplicated() devuelve True/False.\n",
    "# duplicated().sum() nos dice cuántos hay.\n",
    "num_duplicados = df.duplicated().sum()\n",
    "print(f\"Filas duplicadas EXACTAS: {num_duplicados}\")\n",
    "\n",
    "# Truco Pro: Ver cuáles son las duplicadas\n",
    "print(\"\\n--- Mostrando las filas que son copias ---\")\n",
    "print(df[df.duplicated()]) \n",
    "# Nota: Verás que sale el ID 101 (Ana) porque es idéntica a la primera.\n",
    "# Pero NO sale el ID 102 (Beto) porque su email cambió, así que para Pandas no son idénticos.\n",
    "\n",
    "\n",
    "# --- 3. LIMPIEZA NIVEL 1: Duplicados Exactos ---\n",
    "# drop_duplicates() borra solo si TODAS las columnas coinciden\n",
    "df_limpio_exacto = df.drop_duplicates()\n",
    "\n",
    "print(f\"\\n--- 2. Limpieza Exacta (Se fue la copia de Ana) ---\")\n",
    "print(df_limpio_exacto)\n",
    "\n",
    "\n",
    "# --- 4. LIMPIEZA NIVEL 2: Duplicados por Columna (Subset) ---\n",
    "# Problema: Beto (102) aparece dos veces con emails distintos. \n",
    "# Regla de negocio: \"Un ID debe ser único\".\n",
    "# Usamos 'subset' para decirle: \"Si el ID se repite, bórralo\".\n",
    "\n",
    "# keep='first' (por defecto): Se queda con el primero que encontró.\n",
    "# keep='last': Se queda con el último (útil si quieres el dato más reciente).\n",
    "\n",
    "df_sin_repes_id = df.drop_duplicates(subset=['ID'], keep='first')\n",
    "\n",
    "print(f\"\\n--- 3. Limpieza por ID (Se fue el segundo Beto) ---\")\n",
    "print(df_sin_repes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f04e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Carga de Datos ---\n",
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0   \n",
      "1  15.0          8         350.0       165.0    3693          11.5   \n",
      "2  18.0          8         318.0       150.0    3436          11.0   \n",
      "3  16.0          8         304.0       150.0    3433          12.0   \n",
      "4  17.0          8         302.0       140.0    3449          10.5   \n",
      "\n",
      "   model_year origin                       name  \n",
      "0          70    usa  chevrolet chevelle malibu  \n",
      "1          70    usa          buick skylark 320  \n",
      "2          70    usa         plymouth satellite  \n",
      "3          70    usa              amc rebel sst  \n",
      "4          70    usa                ford torino  \n",
      "\n",
      "--- 2. Variable Derivada: KPL ---\n",
      "    mpg   kpl\n",
      "0  18.0  7.65\n",
      "1  15.0  6.38\n",
      "2  18.0  7.65\n",
      "3  16.0  6.80\n",
      "4  17.0  7.22\n"
     ]
    }
   ],
   "source": [
    "#ejercicios 0110\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CARGAR DATOS (Auto MPG) ---\n",
    "# En el PDF cargan un CSV, nosotros usaremos el de la librería directa\n",
    "print(\"--- 1. Carga de Datos ---\")\n",
    "df = sns.load_dataset('mpg')\n",
    "\n",
    "# Limpiamos un poco los nulos antes de empezar (como aprendimos en la 3.3)\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# --- 2. VARIABLES DERIVADAS (Crear información nueva) ---\n",
    "print(\"\\n--- 2. Variable Derivada: Peso en kg ---\")\n",
    "# La columna 'weight' está en libras. Queremos kg.\n",
    "df['weight_kg'] = df['weight'] * 0.453592\n",
    "\n",
    "# Redondeamos a 2 decimales [cite: 704]\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "\n",
    "print(df[['mpg', 'kpl']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Tipos de Datos ---\n",
      "Antes: object\n",
      "Ahora: category\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. TRANSFORMACIÓN DE TIPOS (Categories) ---\n",
    "print(\"\\n--- 3. Tipos de Datos ---\")\n",
    "print(\"Antes:\", df['origin'].dtype)\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(\"Ahora:\", df['origin'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a82ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Binning de Horsepower ---\n",
      "   horsepower horsepower_binned\n",
      "0       130.0    Media Potencia\n",
      "1       165.0    Media Potencia\n",
      "2       150.0    Media Potencia\n",
      "3       150.0    Media Potencia\n",
      "4       140.0    Media Potencia\n",
      "5       198.0     Alta Potencia\n",
      "6       220.0     Alta Potencia\n",
      "7       215.0     Alta Potencia\n",
      "8       225.0     Alta Potencia\n",
      "9       190.0     Alta Potencia\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 4. BINNING (Agrupar Caballos de Fuerza) ---\n",
    "# Vamos a clasificar la potencia ('horsepower') en 3 niveles: Bajo, Medio, Alto.\n",
    "# Usamos histograma para ver los cortes [cite: 913]\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "bin_names = ['Baja Potencia', 'Media Potencia', 'Alta Potencia']\n",
    "print(\"\\n--- 4. Binning de Horsepower ---\")\n",
    "\n",
    "#bajo \n",
    "df['horsepower_binned'] = pd.cut(df['horsepower'], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "#medio\n",
    "\n",
    "\n",
    "#alto\n",
    "print(df[['horsepower', 'horsepower_binned']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8192452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Binning (Rangos) ---\n",
      "     horsepower          hp_bin\n",
      "124       180.0   Alta Potencia\n",
      "117        49.0   Baja Potencia\n",
      "233        78.0   Baja Potencia\n",
      "166       129.0  Media Potencia\n",
      "375        74.0   Baja Potencia\n"
     ]
    }
   ],
   "source": [
    "# Creamos la columna de rangos con pd.cut [cite: 998]\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],\n",
    "                      bins=bin_dividers,\n",
    "                      labels=bin_names,\n",
    "                      include_lowest=True)\n",
    "\n",
    "print(\"\\n--- 4. Binning (Rangos) ---\")\n",
    "print(df[['horsepower', 'hp_bin']].sample(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. DUMMY VARIABLES (One-Hot Encoding) ---\n",
    "# Las IAs no entienden \"Baja Potencia\" o \"Alta Potencia\".\n",
    "# Convertimos esa columna nueva en números (0 y 1)[cite: 1127].\n",
    "print(\"\\n--- 5. Dummy Variables ---\")\n",
    "dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(dummies.head())\n",
    "\n",
    "# (Opcional) Pegarlo al dataframe original\n",
    "df = pd.concat([df, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e074906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 6. NORMALIZACIÓN (Escalado) ---\n",
    "# Vamos a escalar el 'peso' (weight) para que vaya de 0 a 1.\n",
    "# Fórmula: (Valor - Min) / (Max - Min) [cite: 1225-1227]\n",
    "print(\"\\n--- 6. Normalización (Peso) ---\")\n",
    "print(f\"Peso original (Max): {df['weight'].max()}\")\n",
    "\n",
    "df['peso_normalizado'] = (df['weight'] - df['weight'].min()) / (df['weight'].max() - df['weight'].min())\n",
    "\n",
    "print(f\"Peso normalizado (Max): {df['peso_normalizado'].max()}\")\n",
    "print(df[['weight', 'peso_normalizado']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345f6a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. CARGA DE DATOS ---\n",
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0   \n",
      "1  15.0          8         350.0       165.0    3693          11.5   \n",
      "2  18.0          8         318.0       150.0    3436          11.0   \n",
      "\n",
      "   model_year origin                       name  \n",
      "0          70    usa  chevrolet chevelle malibu  \n",
      "1          70    usa          buick skylark 320  \n",
      "2          70    usa         plymouth satellite  \n",
      "------------------------------\n",
      "\n",
      "--- 2. LIMPIEZA (Horsepower) ---\n",
      "Nulos antes: 6\n",
      "Nulos después: 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CARGA DE DATOS (Simulando el CSV)\n",
    "# ==============================================================================\n",
    "print(\"--- 1. CARGA DE DATOS ---\")\n",
    "# El PDF usa pd.read_csv('./auto-mpg.csv'). Nosotros usaremos Seaborn que ya lo trae.\n",
    "df = sns.load_dataset('mpg')\n",
    "\n",
    "# Para que coincida EXACTAMENTE con el PDF, renombramos columnas (aunque ya vienen bien)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "print(df.head(3))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. LIMPIEZA PREVIA (PDF Lines 9-6 a 9-8)\n",
    "# ==============================================================================\n",
    "# El PDF menciona que 'horsepower' tiene signos '?' que hay que borrar.\n",
    "# En el dataset de Seaborn, ya vienen como NaN, así que solo eliminamos los nulos.\n",
    "print(\"\\n--- 2. LIMPIEZA (Horsepower) ---\")\n",
    "print(f\"Nulos antes: {df['horsepower'].isnull().sum()}\")\n",
    "\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "\n",
    "# Aseguramos que sea float (decimal)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "print(f\"Nulos después: {df['horsepower'].isnull().sum()}\")\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606f4414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. VARIABLE DERIVADA (MPG -> KPL) ---\n",
      "    mpg   kpl\n",
      "0  18.0  7.65\n",
      "1  15.0  6.38\n",
      "2  18.0  7.65\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. VARIABLE DERIVADA: MPG a KPL (PDF Line 3)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 3. VARIABLE DERIVADA (MPG -> KPL) ---\")\n",
    "# Fórmula del PDF: 1.60934 km/milla / 3.78541 litros/galón\n",
    "mpg_to_kpl = 1.60934 / 3.78541\n",
    "\n",
    "# Aplicamos la fórmula (Line 3-3)\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "\n",
    "# Redondeamos a 2 decimales (Line 3-7)\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "\n",
    "print(df[['mpg', 'kpl']].head(3))\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f28dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. CAMBIO DE TIPOS DE DATOS ---\n",
      "Tipo original 'origin': object\n",
      "Tipo nuevo 'origin': object\n",
      "\n",
      "Tipo original 'model_year': int64\n",
      "Tipo nuevo 'model_year': category\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. TIPOS DE DATOS (PDF Lines 5 a 8)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 4. CAMBIO DE TIPOS DE DATOS ---\")\n",
    "# El PDF cambia 'origin' y 'model_year' a categoría y luego a string/objeto.\n",
    "# Esto le dice a la IA: \"Oye, el año 70 no es una cantidad, es una etiqueta\".\n",
    "\n",
    "print(\"Tipo original 'origin':\", df['origin'].dtype)\n",
    "df['origin'] = df['origin'].astype('object') # O 'category'\n",
    "print(\"Tipo nuevo 'origin':\", df['origin'].dtype)\n",
    "\n",
    "print(\"\\nTipo original 'model_year':\", df['model_year'].dtype)\n",
    "df['model_year'] = df['model_year'].astype('category')\n",
    "print(\"Tipo nuevo 'model_year':\", df['model_year'].dtype)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8dab33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. BINNING (Rangos de Potencia) ---\n",
      "Límites de los grupos: [ 46.         107.33333333 168.66666667 230.        ]\n",
      "     horsepower         hp_bin\n",
      "17         85.0     Low output\n",
      "140       150.0  Normal output\n",
      "293        71.0     Low output\n",
      "49         86.0     Low output\n",
      "36         88.0     Low output\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 5. BINNING: DE NÚMEROS A GRUPOS (PDF Lines 10 a 11)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 5. BINNING (Rangos de Potencia) ---\")\n",
    "# Queremos dividir la potencia en 3 grupos: Bajo, Normal, Alto.\n",
    "\n",
    "# Paso A: Calcular los cortes (histograma)\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(\"Límites de los grupos:\", bin_dividers)\n",
    "\n",
    "# Paso B: Crear las etiquetas\n",
    "bin_names = ['Low output', 'Normal output', 'High output']\n",
    "\n",
    "# Paso C: Cortar los datos (pd.cut)\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],\n",
    "                      bins=bin_dividers,\n",
    "                      labels=bin_names,\n",
    "                      include_lowest=True)\n",
    "\n",
    "print(df[['horsepower', 'hp_bin']].sample(5))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b256644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 6. DUMMY VARIABLES (Para la IA) ---\n",
      "   Low output  Normal output  High output\n",
      "0       False           True        False\n",
      "1       False           True        False\n",
      "2       False           True        False\n",
      "3       False           True        False\n",
      "4       False           True        False\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. DUMMY VARIABLES (One-Hot Encoding) (PDF Line 13)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 6. DUMMY VARIABLES (Para la IA) ---\")\n",
    "# Convertimos la columna de texto 'hp_bin' en columnas numéricas (0 y 1)\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "\n",
    "print(horsepower_dummies.head(5))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5360e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 7. NORMALIZACIÓN (0 a 1) ---\n",
      "Máximo original: 230.0\n",
      "Máximo normalizado: 1.0\n",
      "   horsepower  horsepower_normalized\n",
      "0       130.0               0.456522\n",
      "1       165.0               0.646739\n",
      "2       150.0               0.565217\n",
      "3       150.0               0.565217\n",
      "4       140.0               0.510870\n",
      "\n",
      "\n",
      "¡PROCESO TERMINADO! Tu DataFrame ya es apto para Inteligencia Artificial.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 7. NORMALIZACIÓN (Escalado Min-Max) (PDF Lines 14 a 15)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 7. NORMALIZACIÓN (0 a 1) ---\")\n",
    "# Queremos que 'horsepower' vaya de 0 a 1 para no confundir a la red neuronal.\n",
    "\n",
    "# Estadística antes\n",
    "print(\"Máximo original:\", df['horsepower'].max())\n",
    "\n",
    "# Fórmula: (X - Min) / (Max - Min)\n",
    "min_val = df['horsepower'].min()\n",
    "max_val = df['horsepower'].max()\n",
    "\n",
    "df['horsepower_normalized'] = (df['horsepower'] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Resultado\n",
    "print(\"Máximo normalizado:\", df['horsepower_normalized'].max())\n",
    "print(df[['horsepower', 'horsepower_normalized']].head(5))\n",
    "\n",
    "print(\"\\n\\n¡PROCESO TERMINADO! Tu DataFrame ya es apto para Inteligencia Artificial.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
