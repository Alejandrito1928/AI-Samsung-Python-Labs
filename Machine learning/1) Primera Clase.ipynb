{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0166ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports Generales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Configuración opcional para ver todas las columnas en pandas\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb43ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones Train: (426, 30)\n",
      "Dimensiones Test: (143, 30)\n",
      "Predicciones (primeros 10): [1 0 0 1 1 0 0 0 0 1]\n",
      "Realidad (primeros 10):     [1 0 0 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 2. Carga y División de Datos (Breast Cancer Dataset)\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Ver la estructura de los datos (opcional)\n",
    "# print(data.DESCR)\n",
    "df_data = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df_target = pd.DataFrame(data['target'], columns=['target'])\n",
    "\n",
    "# División Train/Test (75% Train, 25% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, \n",
    "    data.target, \n",
    "    random_state=42, \n",
    "    test_size=0.25\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones Train: {X_train.shape}\")\n",
    "print(f\"Dimensiones Test: {X_test.shape}\")\n",
    "\n",
    "# Instanciar y Entrenar el Modelo (Decision Tree)\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Ver resultados preliminares\n",
    "print(\"Predicciones (primeros 10):\", y_pred[:10])\n",
    "print(\"Realidad (primeros 10):    \", y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6368bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de aciertos: 137 de 143\n",
      "Precisión manual: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluación Manual (Comparación Visual)\n",
    "# Reshape para crear DataFrames verticales\n",
    "pred_2d = y_pred.reshape(len(y_pred), 1)\n",
    "y_test_2d = y_test.reshape(len(y_test), 1)\n",
    "\n",
    "# Crear DataFrames\n",
    "df1 = pd.DataFrame(pred_2d, columns=['pred'])\n",
    "df2 = pd.DataFrame(y_test_2d, columns=['real'])\n",
    "\n",
    "# Concatenar para comparar lado a lado\n",
    "df_concat = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# Mostrar solo donde coinciden (Aciertos)\n",
    "aciertos = df_concat[df_concat['pred'] == df_concat['real']]\n",
    "print(f\"Número de aciertos: {len(aciertos)} de {len(df_concat)}\")\n",
    "print(f\"Precisión manual: {len(aciertos)/len(df_concat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da357166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos escalados (primeras filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.349138</td>\n",
       "      <td>-1.438513</td>\n",
       "      <td>-0.411726</td>\n",
       "      <td>-0.390479</td>\n",
       "      <td>-1.863662</td>\n",
       "      <td>-1.268607</td>\n",
       "      <td>-0.826171</td>\n",
       "      <td>-0.952866</td>\n",
       "      <td>-1.729368</td>\n",
       "      <td>-0.941541</td>\n",
       "      <td>-0.869714</td>\n",
       "      <td>-1.358653</td>\n",
       "      <td>-0.834815</td>\n",
       "      <td>-0.572307</td>\n",
       "      <td>-0.745868</td>\n",
       "      <td>-0.653983</td>\n",
       "      <td>-0.525835</td>\n",
       "      <td>-0.946771</td>\n",
       "      <td>-0.537817</td>\n",
       "      <td>-0.634495</td>\n",
       "      <td>-0.542685</td>\n",
       "      <td>-1.655655</td>\n",
       "      <td>-0.589864</td>\n",
       "      <td>-0.525560</td>\n",
       "      <td>-1.510669</td>\n",
       "      <td>-0.891500</td>\n",
       "      <td>-0.750217</td>\n",
       "      <td>-0.916711</td>\n",
       "      <td>-0.925086</td>\n",
       "      <td>-0.808411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.204687</td>\n",
       "      <td>0.312640</td>\n",
       "      <td>-0.133673</td>\n",
       "      <td>-0.275880</td>\n",
       "      <td>1.078073</td>\n",
       "      <td>0.863546</td>\n",
       "      <td>0.726314</td>\n",
       "      <td>0.898441</td>\n",
       "      <td>1.178770</td>\n",
       "      <td>1.474377</td>\n",
       "      <td>-0.040223</td>\n",
       "      <td>-0.509623</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>-0.134728</td>\n",
       "      <td>-0.524895</td>\n",
       "      <td>-0.149345</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.237472</td>\n",
       "      <td>-0.430283</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>0.689899</td>\n",
       "      <td>0.194128</td>\n",
       "      <td>-0.051934</td>\n",
       "      <td>1.129415</td>\n",
       "      <td>0.923942</td>\n",
       "      <td>1.222217</td>\n",
       "      <td>1.436560</td>\n",
       "      <td>1.149559</td>\n",
       "      <td>1.569111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.329312</td>\n",
       "      <td>-0.215072</td>\n",
       "      <td>-0.317394</td>\n",
       "      <td>-0.364357</td>\n",
       "      <td>-1.579880</td>\n",
       "      <td>-0.457451</td>\n",
       "      <td>-0.597310</td>\n",
       "      <td>-0.764588</td>\n",
       "      <td>0.275343</td>\n",
       "      <td>-0.501024</td>\n",
       "      <td>-0.581453</td>\n",
       "      <td>0.167984</td>\n",
       "      <td>-0.222791</td>\n",
       "      <td>-0.415329</td>\n",
       "      <td>-1.102403</td>\n",
       "      <td>0.644912</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>-0.190990</td>\n",
       "      <td>0.728842</td>\n",
       "      <td>-0.028967</td>\n",
       "      <td>-0.435901</td>\n",
       "      <td>-0.148985</td>\n",
       "      <td>-0.320159</td>\n",
       "      <td>-0.446032</td>\n",
       "      <td>-1.634396</td>\n",
       "      <td>-0.106752</td>\n",
       "      <td>-0.539891</td>\n",
       "      <td>-0.723713</td>\n",
       "      <td>0.534970</td>\n",
       "      <td>-0.619348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.027403</td>\n",
       "      <td>2.089824</td>\n",
       "      <td>1.046922</td>\n",
       "      <td>0.917584</td>\n",
       "      <td>0.316303</td>\n",
       "      <td>0.562037</td>\n",
       "      <td>1.048527</td>\n",
       "      <td>0.930437</td>\n",
       "      <td>-0.325697</td>\n",
       "      <td>-0.477474</td>\n",
       "      <td>-0.043367</td>\n",
       "      <td>-0.240346</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.079579</td>\n",
       "      <td>-0.751369</td>\n",
       "      <td>-0.286475</td>\n",
       "      <td>0.156326</td>\n",
       "      <td>-0.119314</td>\n",
       "      <td>-1.015472</td>\n",
       "      <td>-0.457385</td>\n",
       "      <td>1.113515</td>\n",
       "      <td>2.165006</td>\n",
       "      <td>1.165793</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.383604</td>\n",
       "      <td>0.860948</td>\n",
       "      <td>1.872819</td>\n",
       "      <td>1.310691</td>\n",
       "      <td>0.152884</td>\n",
       "      <td>0.421636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.828969</td>\n",
       "      <td>0.696001</td>\n",
       "      <td>1.763681</td>\n",
       "      <td>1.783821</td>\n",
       "      <td>-0.333674</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.974660</td>\n",
       "      <td>1.265740</td>\n",
       "      <td>-0.131572</td>\n",
       "      <td>-1.713139</td>\n",
       "      <td>1.600240</td>\n",
       "      <td>0.500901</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>1.491962</td>\n",
       "      <td>0.351882</td>\n",
       "      <td>0.588963</td>\n",
       "      <td>0.754093</td>\n",
       "      <td>2.516764</td>\n",
       "      <td>1.409062</td>\n",
       "      <td>-0.528602</td>\n",
       "      <td>1.471556</td>\n",
       "      <td>0.387568</td>\n",
       "      <td>1.556276</td>\n",
       "      <td>1.385595</td>\n",
       "      <td>-0.577759</td>\n",
       "      <td>0.296680</td>\n",
       "      <td>0.595768</td>\n",
       "      <td>1.232995</td>\n",
       "      <td>0.050452</td>\n",
       "      <td>-1.406351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0    -0.349138     -1.438513       -0.411726  -0.390479        -1.863662   \n",
       "1    -0.204687      0.312640       -0.133673  -0.275880         1.078073   \n",
       "2    -0.329312     -0.215072       -0.317394  -0.364357        -1.579880   \n",
       "3     1.027403      2.089824        1.046922   0.917584         0.316303   \n",
       "4     1.828969      0.696001        1.763681   1.783821        -0.333674   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0         -1.268607       -0.826171            -0.952866      -1.729368   \n",
       "1          0.863546        0.726314             0.898441       1.178770   \n",
       "2         -0.457451       -0.597310            -0.764588       0.275343   \n",
       "3          0.562037        1.048527             0.930437      -0.325697   \n",
       "4          0.628175        0.974660             1.265740      -0.131572   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0               -0.941541     -0.869714      -1.358653        -0.834815   \n",
       "1                1.474377     -0.040223      -0.509623         0.109477   \n",
       "2               -0.501024     -0.581453       0.167984        -0.222791   \n",
       "3               -0.477474     -0.043367      -0.240346         0.004450   \n",
       "4               -1.713139      1.600240       0.500901         1.988514   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0   -0.572307         -0.745868          -0.653983        -0.525835   \n",
       "1   -0.134728         -0.524895          -0.149345         0.074600   \n",
       "2   -0.415329         -1.102403           0.644912         0.074600   \n",
       "3    0.079579         -0.751369          -0.286475         0.156326   \n",
       "4    1.491962          0.351882           0.588963         0.754093   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0             -0.946771       -0.537817                -0.634495   \n",
       "1              0.237472       -0.430283                 0.082891   \n",
       "2             -0.190990        0.728842                -0.028967   \n",
       "3             -0.119314       -1.015472                -0.457385   \n",
       "4              2.516764        1.409062                -0.528602   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0     -0.542685      -1.655655        -0.589864   -0.525560         -1.510669   \n",
       "1      0.041487       0.689899         0.194128   -0.051934          1.129415   \n",
       "2     -0.435901      -0.148985        -0.320159   -0.446032         -1.634396   \n",
       "3      1.113515       2.165006         1.165793    0.997696          0.383604   \n",
       "4      1.471556       0.387568         1.556276    1.385595         -0.577759   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0          -0.891500        -0.750217             -0.916711       -0.925086   \n",
       "1           0.923942         1.222217              1.436560        1.149559   \n",
       "2          -0.106752        -0.539891             -0.723713        0.534970   \n",
       "3           0.860948         1.872819              1.310691        0.152884   \n",
       "4           0.296680         0.595768              1.232995        0.050452   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                -0.808411  \n",
       "1                 1.569111  \n",
       "2                -0.619348  \n",
       "3                 0.421636  \n",
       "4                -1.406351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.1. Estandarización (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar (aprender media/desviación) solo con Train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transformar (aplicar fórmula) a Train y Test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # OJO: Solo transform, no fit\n",
    "\n",
    "# Verificación visual (Convertir a DF para ver mejor)\n",
    "df_scale_after = pd.DataFrame(X_train_scaled, columns=data['feature_names'])\n",
    "print(\"Datos escalados (primeras filas):\")\n",
    "display(df_scale_after.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11eccc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame con Nulos ---\n",
      "      A     B     C    D\n",
      "0   1.0   2.0   3.0  4.0\n",
      "1   5.0   6.0   NaN  8.0\n",
      "2  10.0  11.0  12.0  NaN\n",
      "\n",
      "--- Datos Imputados (Rellenados con media) ---\n",
      "[[ 1.   2.   3.   4. ]\n",
      " [ 5.   6.   7.5  8. ]\n",
      " [10.  11.  12.   6. ]]\n"
     ]
    }
   ],
   "source": [
    "# 4.2. Manejo de Valores Nulos (SimpleImputer)\n",
    "# Crear datos de ejemplo con nulos\n",
    "data_null = [[1.0, 2.0, 3.0, 4.0], \n",
    "             [5.0, 6.0, np.nan, 8.0], \n",
    "             [10.0, 11.0, 12.0, np.nan]]\n",
    "df_null = pd.DataFrame(data_null, columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(\"--- DataFrame con Nulos ---\")\n",
    "print(df_null)\n",
    "\n",
    "# Opción A: Borrar (dropna)\n",
    "# df_dropped = df_null.dropna() # Borra filas con cualquier NaN\n",
    "\n",
    "# Opción B: Imputar (Rellenar con la media)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(df_null.values)\n",
    "data_imputed = imputer.transform(df_null.values)\n",
    "\n",
    "print(\"\\n--- Datos Imputados (Rellenados con media) ---\")\n",
    "print(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aaa123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame tras Mapping y LabelEncoder ---\n",
      "   color size  price classlabel  size_num  classlabel_enc\n",
      "0  green    M   10.1     class2         1               1\n",
      "1    red    L   13.5     class1         2               0\n",
      "2   blue   XL   15.3     class2         3               1\n",
      "\n",
      "--- One Hot Encoding (get_dummies) ---\n",
      "   color_blue  color_green  color_red\n",
      "0       False         True      False\n",
      "1       False        False       True\n",
      "2        True        False      False\n"
     ]
    }
   ],
   "source": [
    "# 4.3. Encoding (LabelEncoder y OneHotEncoder)\n",
    "\n",
    "# Datos de ejemplo: Camisetas\n",
    "df_cat = pd.DataFrame([\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['red', 'L', 13.5, 'class1'],\n",
    "    ['blue', 'XL', 15.3, 'class2']\n",
    "], columns=['color', 'size', 'price', 'classlabel'])\n",
    "\n",
    "# --- Mapeo Manual (Ordinal - Tallas) ---\n",
    "size_mapping = {'XL': 3, 'L': 2, 'M': 1}\n",
    "df_cat['size_num'] = df_cat['size'].map(size_mapping)\n",
    "\n",
    "# --- Label Encoder (Para el Target/Clase) ---\n",
    "enc = LabelEncoder()\n",
    "df_cat['classlabel_enc'] = enc.fit_transform(df_cat['classlabel'].values)\n",
    "\n",
    "print(\"--- DataFrame tras Mapping y LabelEncoder ---\")\n",
    "print(df_cat)\n",
    "\n",
    "# --- One Hot Encoder (Para Colores - Nominales) ---\n",
    "# Usando Pandas get_dummies (más fácil para visualización rápida)\n",
    "dummies = pd.get_dummies(df_cat['color'], prefix='color')\n",
    "print(\"\\n--- One Hot Encoding (get_dummies) ---\")\n",
    "print(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bfd99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['setosa' 'versicolor' 'virginica']\n",
      "Dimensiones X: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports y Carga de Datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "# Cargar Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Nombres de clases para referencia\n",
    "class_names = iris.target_names\n",
    "print(f\"Clases: {class_names}\")\n",
    "print(f\"Dimensiones X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b4f2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntajes de cada fold: [1.         0.96666667 0.93333333 0.96666667 0.9       ]\n",
      "Promedio de exactitud: 0.9533\n",
      "Desviación estándar: 0.0340\n"
     ]
    }
   ],
   "source": [
    "# 2. Validación Cruzada (K-Fold y Stratified K-Fold)\n",
    "\n",
    "# Configurar el validador (5 pliegues)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelo a evaluar\n",
    "model_cv = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Ejecutar Cross Validation\n",
    "# Esto entrena 5 veces y saca 5 notas distintas\n",
    "scores = cross_val_score(model_cv, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"Puntajes de cada fold: {scores}\")\n",
    "print(f\"Promedio de exactitud: {np.mean(scores):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(scores):.4f}\")\n",
    "# Si la desviación es alta, tu modelo es inestable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aba5742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntajes de cada fold: [1.         0.96666667 0.93333333 0.96666667 0.9       ]\n",
      "Promedio de exactitud: 0.9533\n",
      "Desviación estándar: 0.0340\n"
     ]
    }
   ],
   "source": [
    "# 2. Validación Cruzada (K-Fold y Stratified K-Fold)\n",
    "\n",
    "# Configurar el validador (5 pliegues)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelo a evaluar\n",
    "model_cv = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Ejecutar Cross Validation\n",
    "# Esto entrena 5 veces y saca 5 notas distintas\n",
    "scores = cross_val_score(model_cv, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"Puntajes de cada fold: {scores}\")\n",
    "print(f\"Promedio de exactitud: {np.mean(scores):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(scores):.4f}\")\n",
    "# Si la desviación es alta, tu modelo es inestable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eae155f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Entrenar el mejor modelo con datos de train\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Matriz de Confusión\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Evaluación Detallada\n",
    "\n",
    "# Dividimos datos para prueba final (usando el mejor modelo encontrado)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Entrenar el mejor modelo con datos de train\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"--- Matriz de Confusión ---\")\n",
    "print(cm)\n",
    "# Filas: Realidad, Columnas: Predicción\n",
    "\n",
    "# Reporte de Clasificación (Precision, Recall, F1)\n",
    "print(\"\\n--- Reporte de Clasificación ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
